# -*- coding: utf-8 -*-
# @Author  : xuxiaoyang
# @Time    : 2024/11/7 15:15
# @Describe:


import torch.nn as nn
import torch.optim as optim
import argparse
import random
import numpy as np
import torch
import os
import pickle
import ray
from fl.data import datasets

# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
from fl.client.fl_base import ModelConfig
from fl.server.fl_server import FLServer
from fl.model.model import CIFAR10Net, CIFAR100Net, FeMNISTNet, MNISTNet, ResNet18_CIFAR10, ResNet18_CIFAR100, ResNet18_TinyImageNet, TinyImageNetNet, SVHNNet
from fl.model.fedgen_generator import FedGenGenerator
from fl.model.fedftg_generator import create_fedftg_generator
from fl.utils import (
    optim_wrapper,
    scheduler_wrapper,
    plot_client_label_distribution,
    plot_global_metrics,
    plot_worker_metrics,
)
def setup_seed(seed):
    """è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿å®éªŒå¯é‡å¤"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    print(f"éšæœºç§å­å·²è®¾ç½®ä¸º: {seed}")

def train_federated_model(args):
    """
    è®¾ç½®è”é‚¦å­¦ä¹ ç³»ç»Ÿï¼Œè®­ç»ƒæ¨¡å‹å¹¶ç»˜åˆ¶ç»“æœã€‚

    è¯¥å‡½æ•°åˆå§‹åŒ–å¿…è¦çš„é…ç½®ï¼ŒåŒ…æ‹¬ï¼š
    - åŠ è½½æ•°æ®é›†ï¼ˆFEMNIST æˆ– MNISTï¼‰
    - å®šä¹‰æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    - è®¾ç½®è”é‚¦å­¦ä¹ æœåŠ¡å™¨
    - ä½¿ç”¨æŒ‡å®šçš„è”é‚¦ç­–ç•¥è®­ç»ƒæ¨¡å‹
    - ç»˜åˆ¶å…¨å±€å’Œå®¢æˆ·ç«¯çº§åˆ«çš„æ€§èƒ½æŒ‡æ ‡

    Args:
        args: å‘½ä»¤è¡Œå‚æ•°ï¼ŒåŒ…å«æ•°æ®é›†ã€å­¦ä¹ ç‡ã€æ‰¹æ¬¡å¤§å°ç­‰é…ç½®
    """
    # è®¾ç½®éšæœºç§å­
    if args.seed is not None:
        random.seed(args.seed)
        np.random.seed(args.seed)
        torch.manual_seed(args.seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(args.seed)
            
    # Initialize Ray
    ray.init(ignore_reinit_error=True)
    
    # æ ¹æ®æŒ‡å®šçš„æ•°æ®é›†åŠ è½½æ•°æ®
    num_classes = -1
    feature_dim = -1 # ç”Ÿæˆå™¨ç”Ÿæˆçš„ç‰¹å¾çº¬åº¦ï¼Œæ ¹æ®ä¸åŒçš„ç½‘ç»œæ¨¡å‹ä¸åŒ
    if args.dataset.lower() == 'femnist':
        client_list, dataset_dict = datasets.load_feminist_dataset()
        model_fn = FeMNISTNet
        num_classes = 62
        feature_dim = 128
    elif args.dataset.lower() == 'mnist':
        client_list = ["client_" + str(i) for i in range(args.num_clients)]
        dataset_dict = datasets.load_mnist_dataset(client_list, partition=args.partition, beta=args.dir_beta, seed=args.seed, data_fraction=args.data_fraction)
        model_fn = MNISTNet
        num_classes = 10
        feature_dim = 128
    elif args.dataset.lower() == 'svhn':
        client_list = ["client_" + str(i) for i in range(args.num_clients)]
        dataset_dict = datasets.load_svhn_dataset(client_list, partition=args.partition, beta=args.dir_beta, seed=args.seed, data_fraction=args.data_fraction)
        model_fn = SVHNNet
        num_classes = 10
        feature_dim = 256
    elif args.dataset.lower() == 'cifar10':
        client_list = ["client_" + str(i) for i in range(args.num_clients)]
        dataset_dict = datasets.load_cifar10_dataset(client_list, partition=args.partition, beta=args.dir_beta, seed=args.seed, data_fraction=args.data_fraction)
        model_fn = CIFAR10Net
        num_classes = 10
        feature_dim = 256
    elif args.dataset.lower() == 'cifar100':
        client_list = ["client_" + str(i) for i in range(args.num_clients)]
        dataset_dict = datasets.load_cifar100_dataset(client_list, partition=args.partition, beta=args.dir_beta, seed=args.seed, data_fraction=args.data_fraction)
        model_fn = CIFAR100Net
        num_classes = 100
        feature_dim = 512
    elif args.dataset.lower() == 'tinyimagenet':
        client_list = ["client_" + str(i) for i in range(args.num_clients)]
        dataset_dict = datasets.load_tinyimagenet_dataset(client_list, partition=args.partition, beta=args.dir_beta, seed=args.seed, data_fraction=args.data_fraction)
        model_fn = TinyImageNetNet
        num_classes = 200
        feature_dim = 512
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {args.dataset}")
    
     # æ‰“å°æ•°æ®åˆ†å¸ƒä¿¡æ¯
    print(f"\næ•°æ®é›†åˆ’åˆ†æ–¹å¼: {args.partition}")
    if args.partition == "dirichlet":
        print(f"ç‹„åˆ©å…‹é›·åˆ†å¸ƒå‚æ•° dir_beta: {args.dir_beta} (è¾ƒå°çš„å€¼è¡¨ç¤ºæ›´é«˜çš„å¼‚è´¨æ€§)")
    
    print("\nå®¢æˆ·ç«¯æ•°æ®ç»Ÿè®¡:")
    for client in client_list:
        train_labels = [dataset_dict[client]["train_dataset"].Y[i].item() for i in range(len(dataset_dict[client]["train_dataset"]))]
        test_labels = [dataset_dict[client]["test_dataset"].Y[i].item() for i in range(len(dataset_dict[client]["test_dataset"]))]
        print(f"å®¢æˆ·ç«¯ {client}: è®­ç»ƒæ ·æœ¬æ€»æ•°: {len(train_labels)}, æµ‹è¯•æ ·æœ¬æ€»æ•°: {len(test_labels)}")
        #è®­ç»ƒæ ·æœ¬æ ‡ç­¾åˆ†å¸ƒ
        unique, counts = np.unique(train_labels, return_counts=True)
        print(f"  è®­ç»ƒæ ·æœ¬æ ‡ç­¾åˆ†å¸ƒ: {dict(zip(unique, counts))}")
        #æµ‹è¯•æ ·æœ¬æ ‡ç­¾åˆ†å¸ƒ
        unique, counts = np.unique(test_labels, return_counts=True)
        print(f"  æµ‹è¯•æ ·æœ¬æ ‡ç­¾åˆ†å¸ƒ: {dict(zip(unique, counts))}")

    # ç»˜åˆ¶å®¢æˆ·ç«¯æ ‡ç­¾åˆ†å¸ƒ
    if args.plot_distribution:
        plot_client_label_distribution(dataset_dict, args.dataset.lower())
    # å®šä¹‰æŸå¤±å‡½æ•°ï¼ˆåˆ†ç±»ä»»åŠ¡ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼‰
    loss_fn = nn.CrossEntropyLoss

    # é€‰æ‹©ä¼˜åŒ–å™¨
    if args.optimizer.lower() == 'adam':
        optim_fn = optim_wrapper(optim.Adam, lr=args.lr)
    elif args.optimizer.lower() == 'sgd':
        optim_fn = optim_wrapper(optim.SGD, lr=args.lr, momentum=0.9)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–å™¨: {args.optimizer}")
    
    # åˆ›å»ºè°ƒåº¦å™¨å‡½æ•°
    scheduler_fn = scheduler_wrapper(
        scheduler_type=args.scheduler,
        step_size=args.step_size,
        gamma=args.gamma,
        comm_rounds=args.comm_rounds
    )
    
    # æ‰“å°è°ƒåº¦å™¨ä¿¡æ¯
    print(f"ğŸ›ï¸ å­¦ä¹ ç‡è°ƒåº¦å™¨é…ç½®: {args.scheduler}")
    if args.scheduler == 'step':
        print(f"   - æ¯{args.step_size}è½®è¡°å‡{args.gamma}å€")
    elif args.scheduler == 'exp':
        print(f"   - æ¯è½®è¡°å‡{args.gamma}å€")
    elif args.scheduler == 'cosine':
        print(f"   - {args.comm_rounds}è½®ä½™å¼¦é€€ç«")


    # åˆ›å»ºç­–ç•¥ç‰¹å®šçš„è¶…å‚æ•°
    strategy_params = {}
    strategy_params['num_classes'] = num_classes
    

    if args.strategy.lower() == 'fedgen':
        strategy_params['feature_dim'] = feature_dim
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        generator = FedGenGenerator(
            feature_dim=feature_dim,
            num_classes=num_classes,
        ).to(device)
        strategy_params['generator_model'] = generator
    # ä¸ºFedFTGç­–ç•¥åˆ›å»ºç”Ÿæˆå™¨
    elif args.strategy.lower() == 'fedftg':
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        # æ ¹æ®æ•°æ®é›†ç¡®å®šå›¾åƒå°ºå¯¸å’Œé€šé“æ•°
        if args.dataset.lower() in ['mnist', 'femnist']:
            img_channels = 1
            img_size = 28
        else:  # cifar10, cifar100, tinyimagenet
            img_channels = 3
            img_size = 32 if args.dataset.lower() in ['cifar10', 'cifar100'] else 64
            
        # åˆ›å»ºFedFTGç”Ÿæˆå™¨
        fedftg_generator = create_fedftg_generator(
            model_type='standard',  # å¯é€‰ 'standard' æˆ– 'deepinversion'
            z_dim=100,
            num_classes=num_classes,
            img_channels=img_channels,
            img_size=img_size
        )
        
        # æ·»åŠ åˆ°ç­–ç•¥å‚æ•°
        strategy_params['generator'] = fedftg_generator
        strategy_params['generator_lr'] = 0.001
        strategy_params['server_epochs'] = 5  # æœåŠ¡å™¨ç«¯è®­ç»ƒè½®æ•°
    
    # é…ç½®æ¨¡å‹å’Œè®­ç»ƒå‚æ•°
    model_config = ModelConfig(
        model_fn=model_fn,  # æ¨¡å‹å‡½æ•°
        loss_fn=loss_fn,  # æŸå¤±å‡½æ•°
        optim_fn=optim_fn,  # ä¼˜åŒ–å™¨å‡½æ•°
        scheduler_fn=scheduler_fn,  # è°ƒåº¦å™¨å‡½æ•°
        epochs=args.local_epochs,  # æœ¬åœ°è®­ç»ƒè½®æ•°
        batch_size=args.batch_size,  # æ‰¹æ¬¡å¤§å°
    )

    

    # ä½¿ç”¨ç»™å®šå‚æ•°åˆå§‹åŒ–è”é‚¦å­¦ä¹ æœåŠ¡å™¨
    fl_server = FLServer(
        client_list=client_list,  # å®¢æˆ·ç«¯åˆ—è¡¨
        strategy=args.strategy.lower(),  # è”é‚¦å­¦ä¹ ç­–ç•¥
        model_config=model_config,  # æ¨¡å‹é…ç½®
        client_dataset_dict=dataset_dict,  # æ¯ä¸ªå®¢æˆ·ç«¯çš„æ•°æ®é›†å­—å…¸
        seed=args.seed,
        **strategy_params,  # ç›´æ¥è§£åŒ…ç­–ç•¥ç‰¹å®šå‚æ•°
    )

    # å¼€å§‹è”é‚¦å­¦ä¹ è®­ç»ƒè¿‡ç¨‹
    history = fl_server.fit(
        comm_rounds=args.comm_rounds,  # é€šä¿¡è½®æ•°ï¼ˆæˆ–è”é‚¦è®­ç»ƒè½®æ•°ï¼‰
        ratio_client=args.ratio_client,  # æ¯è½®é‡‡æ ·çš„å®¢æˆ·ç«¯æ¯”ä¾‹
    )

    # ç»˜åˆ¶å…¨å±€æŒ‡æ ‡å’Œå®¢æˆ·ç«¯æŒ‡æ ‡
    # åˆ›å»ºä¿å­˜ç›®å½•
    dataset_dir = f"./plots/{args.dataset.lower()}"
    history_dir = f"{dataset_dir}/history"
    os.makedirs(history_dir, exist_ok=True)

    # ä¿å­˜å†å²è®°å½•
    experiment_name = f"{args.strategy}_{args.dataset}_seed{args.seed}"
    with open(f"{history_dir}/{experiment_name}.pkl", "wb") as f:
        pickle.dump(history, f)
        print(f"\nå†å²è®°å½•å·²ä¿å­˜åˆ°: {history_dir}/{experiment_name}.pkl")

    # ç»˜åˆ¶å®¢æˆ·ç«¯æŒ‡æ ‡ï¼ˆå„ä¸ªå®¢æˆ·ç«¯/å·¥ä½œèŠ‚ç‚¹çš„æ€§èƒ½ï¼‰
    plot_worker_metrics(history, experiment_name)
    # ç»˜åˆ¶æ‰€æœ‰è”é‚¦å¯¹æ¯”å›¾
    plot_global_metrics(history, experiment_name)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='è”é‚¦å­¦ä¹ æ¡†æ¶å‚æ•°é…ç½®')

     # è”é‚¦å­¦ä¹ ç®—æ³•ç›¸å…³å‚æ•°
    parser.add_argument('--strategy', type=str, default='fedspd',
                        choices=['fedavg', 'fedprox', 'moon', 'scaffold', 'feddistill', 'fedgen', 'fedspd', 'fedspd-lc', 'fedalone', 'fedftg', 'fedgkd'],
                        help='è”é‚¦å­¦ä¹ ç­–ç•¥')
    
    # æ•°æ®é›†ç›¸å…³å‚æ•°
    parser.add_argument('--dataset', type=str, default='femnist', 
                        choices=['femnist', 'mnist', 'svhn', 'cifar10', 'cifar100', 'tinyimagenet'],
                        help='è¦ä½¿ç”¨çš„æ•°æ®é›† (femnist, mnist, svhn, cifar10, cifar100, tinyimagenet)')
    parser.add_argument('--partition', type=str, default='dirichlet', choices=['iid', 'noiid', 'dirichlet'],
                        help='æ•°æ®åˆ†åŒºæ–¹å¼ (iid æˆ– noiid æˆ– dirichlet)')
    parser.add_argument('--num_clients', type=int, default=10,
                        help='å½“ä½¿ç”¨MNIST/CIFARæ•°æ®é›†æ—¶çš„å®¢æˆ·ç«¯æ•°é‡')
    parser.add_argument('--dir_beta', type=float, default=0.3,
                        help='å½“ä½¿ç”¨dirichletåˆ’åˆ†æ–¹å¼æ—¶çš„ç‹„åˆ©å…‹é›·åˆ†å¸ƒçš„å‚æ•°')
    parser.add_argument('--data_fraction', type=float, default=0.1,
                        help='æ•°æ®é›†é‡‡æ ·æ¯”ä¾‹')
    
    # è®­ç»ƒç›¸å…³å‚æ•°
    parser.add_argument('--batch_size', type=int, default=64, 
                        help='è®­ç»ƒçš„æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--local_epochs', type=int, default=20,
                        help='æ¯ä¸ªå®¢æˆ·ç«¯çš„æœ¬åœ°è®­ç»ƒè½®æ•°')
    parser.add_argument('--comm_rounds', type=int, default=30,
                        help='è”é‚¦å­¦ä¹ çš„é€šä¿¡è½®æ•°')
    parser.add_argument('--ratio_client', type=float, default=0.8,
                        help='æ¯è½®å‚ä¸è®­ç»ƒçš„å®¢æˆ·ç«¯æ¯”ä¾‹')
    parser.add_argument('--lr', type=float, default=0.01,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--optimizer', type=str, default='adam', choices=['adam', 'sgd'],
                        help='ä¼˜åŒ–å™¨ç±»å‹')
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨å‚æ•°
    parser.add_argument('--scheduler', type=str, default='step', 
                        choices=['step', 'exp', 'cosine'],
                        help='è°ƒåº¦å™¨ç±»å‹: step(é˜¶æ¢¯), exp(æŒ‡æ•°), cosine(ä½™å¼¦)')
    parser.add_argument('--step_size', type=int, default=5,
                        help='StepLRæ¯å¤šå°‘è½®è¡°å‡ä¸€æ¬¡')
    parser.add_argument('--gamma', type=float, default=0.8,
                        help='å­¦ä¹ ç‡è¡°å‡å€æ•°')
    parser.add_argument('--patience', type=int, default=3,
                        help='ReduceLROnPlateauçš„è€å¿ƒå€¼')

    # å…¶ä»–å‚æ•°
    parser.add_argument('--seed', type=int, default=42,
                        help='éšæœºç§å­')
    parser.add_argument('--plot_distribution', type=bool, default=True,
                        help='æ˜¯å¦ç»˜åˆ¶å®¢æˆ·ç«¯æ ‡ç­¾åˆ†å¸ƒ')
    
    return parser.parse_args()


# è¿è¡Œè”é‚¦å­¦ä¹ è®¾ç½®å’Œè®­ç»ƒ
if __name__ == "__main__":
    args = parse_arguments()
    setup_seed(args.seed)
    train_federated_model(args)

