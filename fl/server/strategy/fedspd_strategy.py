import torch
import numpy as np
import copy

from fl.aggregation.aggregator import average_weight
from fl.server.strategy.strategy_base import AggregationStrategy


class FedSPDStrategy(AggregationStrategy):
    """FedSPDå†å²æ•™å¸ˆç­–ç•¥
    
    æ ¸å¿ƒè®¾è®¡ï¼š
    - ç»´æŠ¤å†å²å…¨å±€æ¨¡å‹ç¼“å†²åŒº
    - è®¡ç®—å†å²æ¨¡å‹å¹³å‡ä½œä¸ºæ•™å¸ˆ
    - ä¸‹å‘å†å²å¹³å‡æ•™å¸ˆç»™å®¢æˆ·ç«¯è¿›è¡Œè’¸é¦
    
    ä¼˜åŠ¿ï¼š
    - ç¨³å®šçš„å†å²çŸ¥è¯†ï¼ˆé¿å…å•è½®æ³¢åŠ¨ï¼‰
    - ç®€åŒ–æ¥å£ï¼ˆæ— éœ€ç±»åˆ«çº§çŸ¥è¯†ä¼ é€’ï¼‰
    - åŒé‡è’¸é¦ï¼ˆå®¢æˆ·ç«¯åšreps+logitsè’¸é¦ï¼‰
    """
    def __init__(self):
        # å†å²æ¨¡å‹ç®¡ç†
        self.model_buffer = []  # å†å²å…¨å±€æ¨¡å‹ç¼“å†²åŒº
        self.buffer_size = 5    # ç¼“å†²åŒºå¤§å°
        self.eps = 1e-10        # é¿å…é™¤é›¶

    def _update_model_buffer(self, global_weights):
        """æ›´æ–°å†å²æ¨¡å‹ç¼“å†²åŒº"""
        import copy
        # ä¿å­˜å½“å‰å…¨å±€æ¨¡å‹çš„æ·±æ‹·è´åˆ°ç¼“å†²åŒº
        self.model_buffer.append(copy.deepcopy(global_weights))
        
        # å¦‚æœç¼“å†²åŒºå¤§å°è¶…è¿‡é™åˆ¶ï¼Œç§»é™¤æœ€æ—§çš„æ¨¡å‹
        if len(self.model_buffer) > self.buffer_size:
            self.model_buffer.pop(0)
    
    def _build_ensemble_teacher(self):
        """æ„å»ºå†å²æ¨¡å‹å¹³å‡ä½œä¸ºæ•™å¸ˆ"""
        if not self.model_buffer:
            return None
        
        # ç®€å•å¹³å‡æ‰€æœ‰ç¼“å†²åŒºä¸­çš„æ¨¡å‹æƒé‡
        from fl.aggregation.aggregator import average_weight
        return average_weight(self.model_buffer)

    def aggregate(self, server, selected_workers, round_num, global_weights):
        """FedSPDå†å²æ•™å¸ˆèšåˆæ–¹æ³•"""
        if not selected_workers:
            return global_weights, []
        
        # 1. æ›´æ–°å†å²æ¨¡å‹ç¼“å†²åŒº
        self._update_model_buffer(global_weights)
        
        # 2. æ„å»ºå†å²å¹³å‡æ•™å¸ˆ
        ensemble_teacher = self._build_ensemble_teacher()
            
        client_weight_list = []
        sample_num_list = []
        train_loss_list = []
        
        # 3. æ”¶é›†å®¢æˆ·ç«¯è®­ç»ƒç»“æœï¼ˆä¼ é€’å†å²å¹³å‡æ•™å¸ˆï¼‰
        import ray
        
        # 3. æ”¶é›†å®¢æˆ·ç«¯è®­ç»ƒç»“æœï¼ˆä¼ é€’å†å²å¹³å‡æ•™å¸ˆï¼‰
        futures = []
        for client_name, worker in selected_workers.items():
            futures.append(worker.local_train.remote(
                sync_round=round_num,
                weights=global_weights,
                ensemble_weights=ensemble_teacher  # ğŸš€ ä¼ é€’å†å²å¹³å‡æ•™å¸ˆ
            ))
            
        results = ray.get(futures)
        
        for i, client_name in enumerate(selected_workers.keys()):
            client_weight, sample_num, train_loss = results[i]
            
            client_weight_list.append(client_weight)
            sample_num_list.append(sample_num)
            train_loss_list.append(train_loss)
            server.history["workers"][client_name]["train_loss"].append(train_loss)
        
        # 4. èšåˆå…¨å±€æ¨¡å‹æƒé‡
        sample_weights = np.array([max(float(w), self.eps) for w in sample_num_list], dtype=np.float32)
        total_samples = np.sum(sample_weights)
        if total_samples < self.eps:
            sample_weights = np.ones_like(sample_weights, dtype=np.float32) / len(sample_weights)
        else:
            sample_weights = sample_weights / total_samples
            
        global_weight = average_weight(client_weight_list, sample_weights.tolist())
        
        return global_weight, train_loss_list